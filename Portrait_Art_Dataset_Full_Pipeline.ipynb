{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Portrait Art Dataset — Full Pipeline (English, Self‑Contained)\n",
        "\n",
        "MSc Final Project — **Embodied Aesthetic Reconstruction**  \n",
        "This single notebook builds a **high‑quality Portrait Art Dataset** using The Met public API and a curated Tate CSV. \n",
        "It defines schema validation, portrait/face/license filtering, exports CSV/JSONL, and optionally downloads images.\n",
        "\n",
        "**Suggested location:** put this file at the root of your `EmbodiedAestheticReconstruction/` repo.\n",
        "Outputs will be saved under `data/` next to this notebook.\n",
        "\n",
        "Badge for GitHub/Colab usage (replace `YOUR_USER` & `YOUR_REPO` after you upload):  \n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USER/YOUR_REPO/blob/main/Portrait_Art_Dataset_Full_Pipeline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup (install once if needed)\n",
        "If you are on Colab or a fresh environment, run this cell. Otherwise, install from your `requirements.txt` once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "python -V || true\n",
        "pip -V || true\n",
        "pip install -q --upgrade pip\n",
        "pip install -q requests pandas pydantic opencv-python tqdm python-slugify numpy PyYAML pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports & Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import os, io, json, yaml, random, time, glob\n",
        "from pathlib import Path\n",
        "from typing import Optional, List, Iterable, Dict, Any\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "ROOT = Path.cwd()                            # notebook location\n",
        "DATA_DIR = ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "IMAGES_DIR = DATA_DIR / 'images'\n",
        "INTERIM_DIR = DATA_DIR / 'interim'\n",
        "for d in [DATA_DIR, RAW_DIR, IMAGES_DIR, INTERIM_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "ROOT, DATA_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Schema definition (Pydantic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, HttpUrl\n",
        "\n",
        "class PortraitRecord(BaseModel):\n",
        "    artwork_id: str\n",
        "    source_api: str\n",
        "    museum: str\n",
        "    artist_name_en: str\n",
        "    artwork_title_en: Optional[str] = None\n",
        "    year: Optional[str] = None\n",
        "    medium: Optional[str] = None\n",
        "    dimensions: Optional[str] = None\n",
        "    style_period: Optional[str] = None\n",
        "    subject_persons: Optional[List[str]] = None\n",
        "    is_portrait: bool = True\n",
        "    image_url: Optional[HttpUrl] = None\n",
        "    thumbnail_url: Optional[HttpUrl] = None\n",
        "    license: Optional[str] = None\n",
        "    credit_line: Optional[str] = None\n",
        "    width_px: Optional[int] = None\n",
        "    height_px: Optional[int] = None\n",
        "    notes: Optional[str] = None\n",
        "    class Config:\n",
        "        extra = 'ignore'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Utilities (portrait heuristics, license, face detection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "USER_AGENT = \"PortraitArtDataset/1.0 (+https://example.org)\"\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update({\"User-Agent\": USER_AGENT})\n",
        "\n",
        "_PORTRAIT_KEYWORDS = [\"portrait\", \"self-portrait\", \"self portrait\"]\n",
        "_FACE = None\n",
        "\n",
        "def _face():\n",
        "    global _FACE\n",
        "    if _FACE is None:\n",
        "        _FACE = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "    return _FACE\n",
        "\n",
        "def looks_like_portrait(title: str, classification: Optional[str] = None) -> bool:\n",
        "    s = ((title or '') + ' ' + (classification or '')).lower()\n",
        "    return any(k in s for k in _PORTRAIT_KEYWORDS)\n",
        "\n",
        "def license_ok(text: Optional[str], require_public: bool = True) -> bool:\n",
        "    if not text:\n",
        "        return not require_public\n",
        "    return (\"public domain\" in text.lower()) or (\"cc0\" in text.lower()) if require_public else True\n",
        "\n",
        "def _safe_get(url: str, timeout: int = 20) -> Optional[bytes]:\n",
        "    try:\n",
        "        r = SESSION.get(url, timeout=timeout)\n",
        "        if r.status_code == 200:\n",
        "            return r.content\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def face_area_ratio_from_url(url: str) -> float:\n",
        "    data = _safe_get(url)\n",
        "    if not data:\n",
        "        return 0.0\n",
        "    arr = np.frombuffer(data, dtype=np.uint8)\n",
        "    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        return 0.0\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = _face().detectMultiScale(gray, 1.1, 5, minSize=(40, 40))\n",
        "    h, w = gray.shape[:2]\n",
        "    if w*h <= 0:\n",
        "        return 0.0\n",
        "    return float(sum(fw*fh for (_,_,fw,fh) in faces) / (w*h))\n",
        "\n",
        "def passes_face_check(img_url: Optional[str], min_ratio: float = 0.01) -> bool:\n",
        "    if not img_url:\n",
        "        return False\n",
        "    try:\n",
        "        return face_area_ratio_from_url(img_url) >= min_ratio\n",
        "    except Exception:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PortraitFilter (metadata + license + optional face check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PortraitFilter:\n",
        "    def __init__(self, require_public_domain: bool = True, use_face_detection: bool = True):\n",
        "        self.require_public_domain = require_public_domain\n",
        "        self.use_face_detection = use_face_detection\n",
        "    def keep(self, rec: dict) -> bool:\n",
        "        title_ok = looks_like_portrait(rec.get('artwork_title_en',''), rec.get('classification'))\n",
        "        subject_ok = bool(rec.get('subject_persons') or []) or title_ok\n",
        "        if not license_ok(rec.get('license'), self.require_public_domain):\n",
        "            return False\n",
        "        if self.use_face_detection:\n",
        "            url = rec.get('image_url')\n",
        "            if not url or not passes_face_check(url, 0.01):\n",
        "                return False\n",
        "        return subject_ok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fetchers — The Met API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MET_BASE = \"https://collectionapi.metmuseum.org/public/collection/v1\"\n",
        "MET_TERMS = [\"portrait\", \"self-portrait\", \"self portrait\"]\n",
        "\n",
        "def met_search_ids(artist: str) -> List[int]:\n",
        "    ids = set()\n",
        "    for q in MET_TERMS:\n",
        "        r = SESSION.get(f\"{MET_BASE}/search\", params={\"q\": f\"{q} {artist}\", \"hasImages\": \"true\"}, timeout=30)\n",
        "        if r.status_code == 200:\n",
        "            for oid in (r.json().get('objectIDs') or []):\n",
        "                try:\n",
        "                    ids.add(int(oid))\n",
        "                except Exception:\n",
        "                    pass\n",
        "    return list(ids)\n",
        "\n",
        "def met_fetch_object(oid: int) -> Dict[str, Any]:\n",
        "    r = SESSION.get(f\"{MET_BASE}/objects/{oid}\", timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def met_yield_records(artist_en: str) -> Iterable[dict]:\n",
        "    for oid in met_search_ids(artist_en):\n",
        "        try:\n",
        "            o = met_fetch_object(oid)\n",
        "        except Exception:\n",
        "            continue\n",
        "        yield {\n",
        "            'artwork_id': f'met_{oid}',\n",
        "            'source_api': 'met',\n",
        "            'museum': 'The Metropolitan Museum of Art',\n",
        "            'artist_name_en': o.get('artistDisplayName') or artist_en,\n",
        "            'artwork_title_en': o.get('title'),\n",
        "            'year': o.get('objectDate'),\n",
        "            'medium': o.get('medium'),\n",
        "            'dimensions': o.get('dimensions'),\n",
        "            'style_period': o.get('period'),\n",
        "            'subject_persons': o.get('tags') or None,\n",
        "            'image_url': o.get('primaryImage') or o.get('primaryImageSmall'),\n",
        "            'thumbnail_url': o.get('primaryImageSmall') or None,\n",
        "            'license': 'Public Domain' if o.get('isPublicDomain') else None,\n",
        "            'credit_line': o.get('creditLine'),\n",
        "            'notes': o.get('objectName'),\n",
        "            'classification': o.get('classification'),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Fetchers — Tate Local CSV (hand‑picked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _split_subjects(x):\n",
        "    if pd.isna(x) or x is None:\n",
        "        return None\n",
        "    s = str(x)\n",
        "    if ';' in s:\n",
        "        return [t.strip() for t in s.split(';') if t.strip()]\n",
        "    if ',' in s:\n",
        "        return [t.strip() for t in s.split(',') if t.strip()]\n",
        "    return [s.strip()] if s.strip() else None\n",
        "\n",
        "def tate_yield_records(csv_path: str) -> Iterable[dict]:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    req = [\"artistName\",\"title\",\"year\",\"medium\",\"dimensions\",\"imageUrl\",\"thumbnailUrl\"]\n",
        "    for col in req:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Missing required column: {col}\")\n",
        "    for i, row in df.iterrows():\n",
        "        yield {\n",
        "            'artwork_id': f'tate_{int(i)}',\n",
        "            'source_api': 'tate_local',\n",
        "            'museum': 'Tate Britain',\n",
        "            'artist_name_en': str(row.get('artistName','')).strip(),\n",
        "            'artwork_title_en': row.get('title'),\n",
        "            'year': row.get('year'),\n",
        "            'medium': row.get('medium'),\n",
        "            'dimensions': row.get('dimensions'),\n",
        "            'style_period': row.get('style_period', None),\n",
        "            'subject_persons': _split_subjects(row.get('subjectPersons')),\n",
        "            'image_url': row.get('imageUrl'),\n",
        "            'thumbnail_url': row.get('thumbnailUrl'),\n",
        "            'license': row.get('license'),\n",
        "            'credit_line': row.get('creditLine'),\n",
        "            'notes': row.get('notes'),\n",
        "            'classification': row.get('classification'),\n",
        "            'is_portrait': bool(row.get('isPortrait', True)),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Pipeline (combine sources → filter → validate → export)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import ValidationError\n",
        "\n",
        "class Pipeline:\n",
        "    def __init__(self, config: dict):\n",
        "        self.config = config\n",
        "        opts = config.get('options', {})\n",
        "        self.filter = PortraitFilter(\n",
        "            require_public_domain=bool(opts.get('require_public_domain', True)),\n",
        "            use_face_detection=bool(opts.get('use_face_detection', True)),\n",
        "        )\n",
        "\n",
        "    def _enabled(self, key: str) -> bool:\n",
        "        for m in self.config.get('museums', []):\n",
        "            if m.get('key') == key:\n",
        "                return bool(m.get('enabled', False))\n",
        "        return False\n",
        "\n",
        "    def run(self, out_csv: str, out_jsonl: str):\n",
        "        records: List[dict] = []\n",
        "        # MET\n",
        "        if self._enabled('met'):\n",
        "            for a in self.config.get('artists', []):\n",
        "                for rec in met_yield_records(a['en']):\n",
        "                    if self.filter.keep(rec):\n",
        "                        records.append(rec)\n",
        "        # Tate local\n",
        "        if self._enabled('tate_local'):\n",
        "            csv_path = str(RAW_DIR / 'tate_selected.csv')\n",
        "            if os.path.exists(csv_path):\n",
        "                for rec in tate_yield_records(csv_path):\n",
        "                    if self.filter.keep(rec):\n",
        "                        records.append(rec)\n",
        "        # Validate\n",
        "        valid = []\n",
        "        for r in records:\n",
        "            try:\n",
        "                valid.append(PortraitRecord(**r).model_dump())\n",
        "            except ValidationError:\n",
        "                pass\n",
        "        # Export\n",
        "        pd.DataFrame(valid).to_csv(out_csv, index=False)\n",
        "        with open(out_jsonl, 'w', encoding='utf-8') as f:\n",
        "            for row in valid:\n",
        "                f.write(json.dumps(row, ensure_ascii=False) + '\\n')\n",
        "        return valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Load or create `artists.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg_path = ROOT / 'artists.yaml'\n",
        "if not cfg_path.exists():\n",
        "    sample_cfg = {\n",
        "        'museums': [\n",
        "            {'name': 'The Metropolitan Museum of Art', 'key': 'met', 'enabled': True},\n",
        "            {'name': 'Tate Britain (Local CSV)', 'key': 'tate_local', 'enabled': False},\n",
        "        ],\n",
        "        'artists': [\n",
        "            {'en': 'Jean-Auguste-Dominique Ingres'},\n",
        "            {'en': 'Thomas Gainsborough'},\n",
        "        ],\n",
        "        'options': {'min_image_width': 600, 'require_public_domain': True, 'use_face_detection': True}\n",
        "    }\n",
        "    with open(cfg_path, 'w', encoding='utf-8') as f:\n",
        "        yaml.safe_dump(sample_cfg, f, allow_unicode=True, sort_keys=False)\n",
        "with open(cfg_path, 'r', encoding='utf-8') as f:\n",
        "    CONFIG = yaml.safe_load(f)\n",
        "CONFIG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Run pipeline → export CSV/JSONL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_csv = str(INTERIM_DIR / 'portrait_art_dataset.csv')\n",
        "out_jsonl = str(INTERIM_DIR / 'portrait_art_dataset.jsonl')\n",
        "pipe = Pipeline(CONFIG)\n",
        "rows = pipe.run(out_csv, out_jsonl)\n",
        "print(f\"Saved: {out_csv} | {out_jsonl} | rows={len(rows)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Preview dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(out_csv) if os.path.exists(out_csv) else pd.DataFrame()\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. (Optional) Download images to `data/images/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from slugify import slugify\n",
        "\n",
        "def download(url: str, path: Path) -> bool:\n",
        "    try:\n",
        "        r = SESSION.get(url, timeout=30)\n",
        "        if r.status_code == 200:\n",
        "            with open(path, 'wb') as f:\n",
        "                f.write(r.content)\n",
        "            return True\n",
        "    except Exception:\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "download_count = 0\n",
        "if os.path.exists(out_jsonl):\n",
        "    with open(out_jsonl, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, total=len(open(out_jsonl, 'r', encoding='utf-8').read().splitlines())):\n",
        "            row = json.loads(line)\n",
        "            url = row.get('image_url')\n",
        "            if not url:\n",
        "                continue\n",
        "            name = slugify(f\"{row.get('source_api')}_{row.get('artist_name_en')}_{row.get('artwork_title_en')}\")\n",
        "            out_path = IMAGES_DIR / f\"{name}.jpg\"\n",
        "            if out_path.exists():\n",
        "                continue\n",
        "            if download(url, out_path):\n",
        "                download_count += 1\n",
        "download_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Show random downloaded images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "jpgs = list(IMAGES_DIR.glob('*.jpg'))\n",
        "sample = random.sample(jpgs, min(6, len(jpgs))) if jpgs else []\n",
        "for p in sample:\n",
        "    display(Image.open(p))\n",
        "len(jpgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Quick stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not df.empty:\n",
        "    print('By museum:')\n",
        "    display(df['museum'].value_counts().to_frame('count'))\n",
        "    print('By artist:')\n",
        "    display(df['artist_name_en'].value_counts().head(10).to_frame('count'))\n",
        "else:\n",
        "    print('No data yet. Try re-running the pipeline or check API connectivity.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Next steps (connect with matcher)\n",
        "- Use `data/interim/portrait_art_dataset.jsonl` + `data/images/` in your *match-only* system.\n",
        "- Example (run from the matcher repo):\n",
        "```bash\n",
        "python indexing/build_index.py \\\n",
        "  --dataset_jsonl /absolute/path/to/EmbodiedAestheticReconstruction/data/interim/portrait_art_dataset.jsonl \\\n",
        "  --images_dir    /absolute/path/to/EmbodiedAestheticReconstruction/data/images\n",
        "```\n",
        "\n",
        "**Tip:** Keep code/artifacts (CSV/JSONL) in Git; keep large image files out of Git (use `.gitignore`)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
