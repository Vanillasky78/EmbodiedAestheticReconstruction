import time
import numpy as np
import os, cv2, av
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from processors.live_pose import LivePose

st.markdown("### ğŸ¥ Live Mirror + Pose (Auto-capture on stillness)")

# ---- æ§ä»¶
with st.expander("Live settings", expanded=True):
    conf = st.slider("Pose confidence", 0.05, 0.9, 0.4, 0.05)
    mirror = st.checkbox("Mirror preview", value=True)
    still_seconds = st.number_input("Stillness required (seconds)", 1.0, 10.0, 5.0, 0.5)  # å·²æ”¹ä¸º 5s é»˜è®¤
    sensitivity = st.slider("Motion sensitivity (lower = æ›´æ•æ„Ÿ)", 0.5, 5.0, 2.0, 0.1)
    manual_col = st.empty()

# ---- çŠ¶æ€
if "live_pose" not in st.session_state:
    st.session_state.live_pose = LivePose(yolo_weights="yolov8n-pose.pt", conf=conf)
else:
    st.session_state.live_pose.conf = conf

# ä¾› stillness æ£€æµ‹ä½¿ç”¨çš„çŠ¶æ€
state = st.session_state
state.prev_kps = state.get("prev_kps", None)          # ä¸Šä¸€å¸§å…³é”®ç‚¹
state.last_move_ts = state.get("last_move_ts", time.time())
state.last_saved_path = state.get("last_saved_path", None)
state.auto_saved_flag = state.get("auto_saved_flag", False)

RTC_CONFIGURATION = {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}

def _overlay_progress(img: np.ndarray, remain: float, total: float):
    """åœ¨ç”»é¢åº•éƒ¨ç»˜åˆ¶è¿›åº¦æ¡ + æ–‡æœ¬"""
    h, w = img.shape[:2]
    pad = 12
    bar_w = int(w * 0.6)
    bar_h = 10
    x0 = (w - bar_w) // 2
    y0 = h - pad - bar_h
    # èƒŒæ™¯æ§½
    cv2.rectangle(img, (x0, y0), (x0 + bar_w, y0 + bar_h), (60, 60, 60), -1)
    # å·²é™æ­¢æ—¶é•¿
    elapsed = max(0.0, total - max(0.0, remain))
    frac = float(np.clip(elapsed / total, 0, 1))
    cv2.rectangle(img, (x0, y0), (x0 + int(bar_w * frac), y0 + bar_h), (0, 200, 0), -1)
    # æ–‡æœ¬
    txt = f"Hold still: {remain:.1f}s"
    cv2.putText(img, txt, (x0, y0 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (10, 220, 10), 2, cv2.LINE_AA)

def _kps_motion(prev_kps, cur_kps, norm_scale):
    """
    è®¡ç®—å…³é”®ç‚¹é—´çš„å¹³å‡ä½ç§»ï¼ˆå½’ä¸€åŒ–ï¼‰ã€‚norm_scale ç”¨ç”»é¢å¯¹è§’çº¿åƒç´ ï¼›sensitivity è¶Šå°è¶Šæ•æ„Ÿã€‚
    åªåœ¨ä¸¤å¸§éƒ½æœ‰çš„å…³é”®ç‚¹è®¡ç®—ã€‚
    """
    if prev_kps is None or cur_kps is None:
        return None
    mask = (prev_kps[:, 0] > 0) & (prev_kps[:, 1] > 0) & (cur_kps[:, 0] > 0) & (cur_kps[:, 1] > 0)
    if mask.sum() < 4:
        return None
    d = np.linalg.norm(prev_kps[mask] - cur_kps[mask], axis=1).mean()
    return d / (norm_scale + 1e-6)

def _save_frame(bgr: np.ndarray, path: str):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    cv2.imwrite(path, bgr)

def _video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    bgr = frame.to_ndarray(format="bgr24")

    # å§¿æ€æ¨ç† + éª¨éª¼ç»˜åˆ¶ï¼Œæ‹¿åˆ°å…³é”®ç‚¹
    vis, cur_kps = state.live_pose.infer_and_draw(bgr, mirror=mirror, return_kps=True)

    # è¿åŠ¨æ£€æµ‹ï¼ˆåŸºäºå…³é”®ç‚¹ä½ç§»ï¼‰
    h, w = vis.shape[:2]
    diag = float(np.hypot(h, w))  # å½’ä¸€åŒ–å°ºåº¦ï¼šç”»é¢å¯¹è§’çº¿
    motion = _kps_motion(state.prev_kps, cur_kps, norm_scale=diag)
    now = time.time()

    # é˜ˆå€¼ï¼šä»¥ sensitivity è½¬æ¢ä¸ºâ€œå…è®¸çš„å½’ä¸€åŒ–ä½ç§»â€
    # sensitivity è¶Šå°é˜ˆå€¼è¶Šå° -> æ›´å®¹æ˜“åˆ¤å®šä¸ºâ€œåœ¨åŠ¨â€
    motion_thresh = 0.002 * sensitivity  # ç»éªŒå€¼ï¼š0.002 å¯¹åº”è½»å¾®æŠ–åŠ¨

    if motion is None or motion > motion_thresh:
        state.last_move_ts = now
        state.auto_saved_flag = False  # ä¸€æ—¦åŠ¨äº†ï¼Œä¸‹æ¬¡å¯å†æ¬¡è§¦å‘æŠ“æ‹

    remain = max(0.0, still_seconds - (now - state.last_move_ts))
    _overlay_progress(vis, remain, still_seconds)

    # æ»¡è¶³é™æ­¢ 5s è‡ªåŠ¨æŠ“æ‹
    if remain <= 0 and (not state.auto_saved_flag):
        save_path = "data/interim/locked_frame.jpg"
        # ä¿å­˜å åŠ éª¨éª¼çš„ç”»é¢ï¼ˆé•œåƒä¸€è‡´ï¼‰
        _save_frame(vis, save_path)
        state.last_saved_path = save_path
        state.auto_saved_flag = True
        # åœ¨ç”»é¢ä¸Šæ‰“ä¸ª â€œSaved!â€ æç¤º
        cv2.putText(vis, "Saved!", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 240, 0), 3, cv2.LINE_AA)

    state.prev_kps = cur_kps
    return LivePose.avframe_from_bgr(vis)

webrtc_ctx = webrtc_streamer(
    key="live-pose-mirror-stillness",
    mode=WebRtcMode.SENDRECV,
    rtc_configuration=RTC_CONFIGURATION,
    media_stream_constraints={"video": True, "audio": False},
    video_frame_callback=_video_frame_callback,
)

# æ‰‹åŠ¨ä¿å­˜æŒ‰é’®ï¼ˆå¯é€‰ï¼‰
if manual_col.button("ğŸ“¸ Save frame (manual)"):
    if webrtc_ctx and webrtc_ctx.video_receiver:
        frame = webrtc_ctx.video_receiver.get_frame(timeout=2.0)
        bgr = frame.to_ndarray(format="bgr24")
        vis, _ = state.live_pose.infer_and_draw(bgr, mirror=mirror, return_kps=True)
        save_path = "data/interim/locked_frame.jpg"
        _save_frame(vis, save_path)
        state.last_saved_path = save_path
        st.success(f"Saved â†’ {save_path}")
    else:
        st.error("No video frame yet â€” please allow camera and wait a second.")

# ä¿å­˜ç»“æœæç¤º
if state.last_saved_path:
    st.caption(f"Last saved: {state.last_saved_path}")
