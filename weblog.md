Embodied Aesthetic Reconstruction Against Disciplinary Norms is a long term research and development process based on motion capture generative AI computational aesthetics and curatorial matching and this weblog documents the iterative evolution of the system in a continuous and reflective manner

Week 1 and Week 2 focus on early conceptual formation the exploration begins from embodied aesthetics posthuman theory and disciplinary norms and slowly evolves toward a system questioning how AI interprets and constructs bodies and during this stage initial inspirations come from the idea that AI both recognises and misrecognises the human form which opens the conceptual space for an embodied reconstruction system

Week 3 introduces the study of CLIP embeddings and image text similarity experiments and these early computational tests verify the feasibility of embedding based retrieval leading toward the idea that large scale artistic image databases can be searched matched and curated using multimodal embeddings and the technical foundation of open clip is established in this phase

Week 4 centers on pose estimation experiments and YOLOv8 Pose is tested extensively and its 17 keypoint skeleton becomes the core structure for interpreting body configuration and this leads to the first real movement focused prototype where motion becomes a parameter for aesthetic mapping

Week 5 marks the construction of the first running prototype built with Streamlit enabling a live camera feed capture process and during this stage a stillness based trigger is explored and the system gains the ability to capture frames in response to bodily stability which strengthens the embodied aspect of interaction

Week 6 expands the artwork database by collecting preparing and curating datasets from local museum collections the Metropolitan Museum of Art and the Art Institute of Chicago and this forms the mixed dataset that represents a wide range of portrait and figurative imagery which becomes necessary for diverse matching results

Week 7 shifts attention to backend engineering and FastAPI is introduced as the system engine enabling structured endpoints for matching metadata querying and embedding retrieval and this architectural step separates front end interaction from computational processing creating a stable scalable workflow

Week 8 introduces pose embeddings through a new vectorisation method encoding keypoints into numerical representations and hybrid similarity is proposed combining clip similarity and pose similarity and the system therefore becomes multimodal linking bodily geometry with visual semantics which dramatically improves the accuracy and embodiment of matching results

Week 9 focuses on curatorial interface refinement the front end becomes visually balanced using a dual panel layout where the left side displays the live skeleton and camera feed while the right side presents the curated artwork match along with artist year and estimated value and this creates an exhibition like presentation mode

Week 10 enhances personalisation through new modes such as portrait only mode and high value mode and the system begins to operate with curatorial intention and aesthetic logic rather than pure algorithmic matching and this pushes it towards an artistic tool instead of a technical demo

Week 11 integrates the mixed index from all museums producing a unified embedding space and increases the dataset size beyond six hundred artworks and the matching engine becomes robust and stable providing reliable and diverse match outputs

Week 12 and Week 13 are dedicated to optimisation debugging and performance stabilisation with specific focus on Apple Silicon Mac M series hardware and adjustments are made for YOLO Pose inference and clip processing ensuring smooth real time interaction

Week 14 finalises the project with outcome production including exhibition images video documentation and preparation of final presentation materials and the system reaches a complete MVP state demonstrating the full pipeline from motion capture to curatorial artwork matching and embodied aesthetic reflection

Throughout the entire development the guiding intention remains consistent to challenge disciplinary norms of the body reveal the imposed standards embedded in computational aesthetic systems and reconstruct a diverse and playful understanding of beauty through motion based AI curation

Embodied Aesthetic Reconstruction Timeline
──────────────────────────────────────────

Q1 Concept and Foundations
──────────────────────────
Week 1 2   Early theory research on embodiment computational aesthetics and disciplinary norms
Week 3     CLIP multimodal experiments and small retrieval tests
Week 4     Motion capture experiments using YOLOv8 Pose and early skeleton processing
Week 5     First Streamlit prototype with real time capture and stillness detection

Q2 Dataset and Architecture
──────────────────────────
Week 6     Multi museum dataset curation Local MET AIC preparation and metadata structuring
Week 7     FastAPI backend construction with full endpoint structure
Week 8     Pose embeddings and hybrid similarity system introduced

Q3 MVP Build
──────────────────────────
Week 9     Curatorial UI design dual panel layout and visual refinement
Week 10    Personalised modes portrait only and high value matching logic
Week 11    Mixed global index creation with more than six hundred artworks

Q4 Finalisation
──────────────────────────
Week 12 13 Performance optimisation Apple Silicon support bug fixes and stability work
Week 14    Outcome production documentation and final presentation materials

