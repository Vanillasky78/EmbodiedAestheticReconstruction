
````markdown
# Embodied Aesthetic Reconstruction  
*Final MSc Project â€” University of the Arts London (CCI)*  

---

## ğŸ“– Project Statement  
"**Embodied Aesthetic Reconstruction Against Disciplinary Norms**" is a research project on a personalised artistic image-generation system based on motion capture and generative AI, creating playful and artistic outputs that correspond to each individualâ€™s body shape.

The project aims to challenge the body anxiety produced by standardised and homogenised ideals of the â€œperfect body.â€ By using motion-capture technology to scan each personâ€™s physical form, and an AI-driven artwork database to automatically match suitable portraits or fashion silhouettes, the system highlights that every individual possesses their own complete aesthetic presence and value. What is considered perfect â€” a beautiful body â€” should inherently be diverse and unique.

---

## 1. System Overview  
This MVP implements a fully functional real-time pose-driven curatorial AI system combining:

- YOLOv8-Pose for live keypoint detection  
- OpenCLIP (ViT-B/32) for visual embeddings  
- Hybrid similarity scoring (CLIP + Pose fusion)  
- Curated multi-museum portrait dataset  
- Streamlit frontend + FastAPI backend  
- Stillness-triggered auto-capture (3â€“5 seconds)  
- Real-time artwork display with metadata (artist / year / value)  

**Pipeline:**  
Camera â†’ Pose Estimation â†’ Embedding Fusion â†’ Artwork Matching â†’ Curated Output

---

## 2. Repository Structure

```text
EmbodiedAestheticReconstruction/
â”‚
â”œâ”€â”€ backend/                     # FastAPI backend engine
â”‚   â”œâ”€â”€ main.py                  # API entrypoint
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ utils_pose.py            # Keypoint â†’ vector encoder
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ pose_matcher.py      # Hybrid pose + CLIP matcher
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â””â”€â”€ yolov8n-pose.pt
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ build_embeddings.py
â”‚       â”œâ”€â”€ build_pose_embeddings.py
â”‚       â””â”€â”€ build_mixed_index.py
â”‚
â”œâ”€â”€ frontend/                    # Streamlit UI
â”‚   â”œâ”€â”€ app_frontend.py
â”‚   â”œâ”€â”€ app_curatorial.py
â”‚   â””â”€â”€ yolov8n-pose.pt
â”‚
â”œâ”€â”€ data/                        # Art datasets (local + MET + AIC)
â”‚   â”œâ”€â”€ mixed/                   # Final merged index used by MVP
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ embeddings.npy
â”‚   â”‚   â”œâ”€â”€ pose_embeddings.npy
â”‚   â”‚   â””â”€â”€ embeddings_meta.csv
â”‚   â”œâ”€â”€ local/
â”‚   â”œâ”€â”€ met/
â”‚   â””â”€â”€ aic/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_check.py           
â”‚   â”œâ”€â”€ start_local.sh           
â”‚   â””â”€â”€ start_local.bat          
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## 3. Installation  

### **3.1 Clone the repository**
```bash
git clone https://github.com/Vanillasky78/EmbodiedAestheticReconstruction.git
cd EmbodiedAestheticReconstruction
```

### **3.2 Create environment (Python 3.10 recommended)**
```bash
conda create -n ear-mvp python=3.10 -y
conda activate ear-mvp
```

### **3.3 Install dependencies**
```bash
pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt
```

---

## 4. Running the System  

### **4.1 Start backend**
```bash
uvicorn backend.main:app --host 127.0.0.1 --port 8000 --reload
```

### **4.2 Start frontend**
```bash
streamlit run frontend/app_frontend.py
```

Access the app at:  
ğŸ‘‰ http://localhost:8501

---

## 5. How It Works  

### **1. Motion Capture**  
YOLOv8-Pose extracts 17 keypoints from the live camera stream.

### **2. Stillness Detection**  
The system auto-captures when stable for 3â€“5 seconds.

### **3. Embedding Fusion**  
- **CLIP embedding** â†’ semantic appearance  
- **Pose embedding** â†’ structural geometry  

### **4. Database Matching**  
Each artwork stores:  
- CLIP embedding  
- Pose embedding  
- Metadata (artist, title, year)  
- Optional estimated value  

### **5. Hybrid Similarity Formula**
```text
final_score = 0.65 * CLIP + 0.35 * Pose
```

### **6. Output Rendering**  
Matched artwork is displayed with:  
- Yellow metadata label (value, year, artist)  
- Pink pose metrics  
- Symmetric dual-panel layout  

---

## 6. Rebuild Indexes (Optional)

### **6.1 Build CLIP embeddings**
```bash
python -m backend.tools.build_embeddings --museum_dir data/local
```

### **6.2 Build pose embeddings**
```bash
python -m backend.tools.build_pose_embeddings --museum_dir data/local --device cpu
```

### **6.3 Build mixed global index**
```bash
python -m backend.tools.build_mixed_index
```

---

## 7. Data Requirements

```text
data/<museum>/
â”‚   images/
â”‚   embeddings.npy
â”‚   pose_embeddings.npy
â”‚   embeddings_meta.csv
```

Default dataset used:

```text
data/mixed/
```

---

## 8. System Architecture Diagram

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ğŸ‘© Audience          â”‚
â”‚  Moves or stands in front  â”‚
â”‚  of camera (pose changes)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¨ Streamlit Frontend (UI)
â”‚   1ï¸âƒ£ Captures camera input
â”‚   2ï¸âƒ£ Detects stillness
â”‚   3ï¸âƒ£ Sends image to API
â”‚   4ï¸âƒ£ Displays matched artwork
â”‚
â”‚   Modes:
â”‚     â€¢ Local (PoseMatcher)
â”‚     â€¢ Remote (FastAPI)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        âš™ï¸ FastAPI Backend
â”‚   1ï¸âƒ£ YOLOv8-Pose
â”‚   2ï¸âƒ£ OpenCLIP embeddings
â”‚   3ï¸âƒ£ Hybrid similarity fusion
â”‚
â”‚   Endpoints:
â”‚     - /match
â”‚     - /list_museums
â”‚     - /metadata/{museum}/{file}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ğŸ—‚ï¸ Data Layer
â”‚   - images/
â”‚   - embeddings.npy
â”‚   - pose_embeddings.npy
â”‚   - embeddings_meta.csv
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Outcome Demonstration  

### ğŸ“¸ *Insert your outcome images here*

```markdown
![Outcome 1](outcome_1.jpg)
![Outcome 2](outcome_2.jpg)
```

### ğŸ¥ *Project Video*  
https://vimeo.com/1138944508

---

## 10. Features  
```text
â€¢ Motion Capture Input â†’ extract pose landmarks via YOLOv8-Pose  
â€¢ Cross-modal Embeddings â†’ fuse pose + CLIP  
â€¢ Generative Output:
    - Visual: stylised portraits (SD/DreamBooth optional)
    - Audio: soundscape generation (RAVE planned)
â€¢ Ethics by Design â†’ consent gate, bias awareness, data toggle
```

---

## 11. Credit  
**Author:** Xinyi Zhang  
**Programme:** MSc Computing and Creative Industry  
**Institute:** UAL â€” Creative Computing Institute  
**Year:** 2025  

---

