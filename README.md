# Embodied Aesthetic Reconstruction  
*Final MSc Project â€” University of the Arts London (CCI)*  

## Project Statement  
"Embodied Aesthetic Reconstruction Against Disciplinary Norms" is a research project on a personalised artistic image-generation system based on motion capture and generative AI, creating playful and artistic outputs that correspond to each individualâ€™s body shape. 
It aims to break the body anxiety caused by standardised and homogenised ideals of the â€œperfect body.â€ By using motion-capture technology to scan each personâ€™s physical form, and an AI-driven image database to automatically match suitable artworks (or fashion silhouettes), the project highlights that every individual possesses their own complete aesthetic presence and value. What is considered perfect (a beautiful body) should inherently be diverse and unique.  

## 1. System Overview  
This MVP implements a fully functional real-time pose-driven curatorial AI system combining:

â€¢ YOLOv8-Pose for live keypoint detection  
â€¢ OpenCLIP (ViT-B/32) for image embeddings  
â€¢ Hybrid similarity scoring  
â€¢ Curated multi-museum image dataset  
â€¢ Streamlit frontend + FastAPI backend  
â€¢ Stillness-triggered auto-capture (3â€“5 seconds)  
â€¢ Real-time artwork display with metadata (artist / year / value)  

Pipeline:  
Camera â†’ Pose Estimation â†’ Embedding Fusion â†’ Artwork Matching â†’ Curated Output

## 2. Repository Structure
EmbodiedAestheticReconstruction/
â”‚
â”œâ”€â”€ backend/                     # FastAPI backend engine
â”‚   â”œâ”€â”€ main.py                  # API entrypoint
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ utils_pose.py            # Keypoint â†’ vector encoder
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ pose_matcher.py      # Hybrid pose + CLIP matcher
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â””â”€â”€ yolov8n-pose.pt
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ build_embeddings.py
â”‚       â”œâ”€â”€ build_pose_embeddings.py
â”‚       â””â”€â”€ build_mixed_index.py
â”‚
â”œâ”€â”€ frontend/                    # Streamlit UI
â”‚   â”œâ”€â”€ app_frontend.py
â”‚   â”œâ”€â”€ app_curatorial.py
â”‚   â””â”€â”€ yolov8n-pose.pt
â”‚
â”œâ”€â”€ data/                        # Art datasets (local + MET + AIC)
â”‚   â”œâ”€â”€ mixed/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ embeddings.npy
â”‚   â”‚   â”œâ”€â”€ pose_embeddings.npy
â”‚   â”‚   â””â”€â”€ embeddings_meta.csv
â”‚   â”œâ”€â”€ local/
â”‚   â”œâ”€â”€ met/
â”‚   â””â”€â”€ aic/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_check.py
â”‚   â”œâ”€â”€ start_local.sh
â”‚   â””â”€â”€ start_local.bat
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

## 3. Installation
1. Clone the repository

git clone https://github.com/Vanillasky78/EmbodiedAestheticReconstruction.git
cd EmbodiedAestheticReconstruction

2. Create environment (Python 3.10 recommended)

conda create -n ear-mvp python=3.10 -y
conda activate ear-mvp

3. Install backend + frontend dependencies

pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt

## 4. Running the System
1. Start backend:

uvicorn backend.main:app --host 127.0.0.1 --port 8000 --reload
2. Start Frontend:

streamlit run frontend/app_frontend.py
3. The app will open at:

http://localhost:8501

## 5. How It Works
1. Motion Capture  
   YOLOv8-Pose extracts 17 keypoints from camera input in real time.

2. Stillness Detection  
   A 3â€“5 second stability window auto-triggers the capture.

3. Embedding Fusion  
   â€¢ CLIP embedding â†’ semantic meaning  
   â€¢ Pose embedding â†’ structural geometry  

4. Database Matching  
   Each artwork includes:  
   - CLIP embedding  
   - Pose embedding  
   - Metadata (artist, title, year)  
   - Optional price estimation  

5. Hybrid Similarity  

final_score = 0.65 * CLIP + 0.35 * Pose

6. Output  
   The matched artwork appears on the right panel with:  
   - Yellow label (value, year, artist)  
   - Pose overlay  
   - Symmetric full-screen layout

## 6. Optional: Rebuild Indexes
1. Build CLIP embeddings
python -m backend.tools.build_embeddings --museum_dir data/local

2. Build pose embeddings
python -m backend.tools.build_pose_embeddings --museum_dir data/local --device cpu

3. Build mixed index
python -m backend.tools.build_mixed_index

## 7. Data Requirements
Each dataset folder (local / met / aic) must contain:

data/<museum>/
â”‚   images/
â”‚   embeddings.npy
â”‚   pose_embeddings.npy
â”‚   embeddings_meta.csv

The system defaults to:
data/mixed/

## 8. System Architecture (Text Diagram)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ğŸ‘© Audience          â”‚
â”‚  Moves or stands in front  â”‚
â”‚  of camera (pose changes)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¨ Streamlit Frontend (UI)
â”‚  1ï¸âƒ£ Captures camera input
â”‚  2ï¸âƒ£ Detects stillness
â”‚  3ï¸âƒ£ Sends image to API
â”‚  4ï¸âƒ£ Displays matched artwork
â”‚
â”‚  Modes:
â”‚   â€¢ Local (PoseMatcher)
â”‚   â€¢ Remote (FastAPI)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   âš™ï¸ FastAPI Backend
â”‚  Receives image â†’ matching:
â”‚   1ï¸âƒ£ YOLOv8-Pose
â”‚   2ï¸âƒ£ OpenCLIP
â”‚   3ï¸âƒ£ Hybrid similarity
â”‚
â”‚  Endpoints:
â”‚   - /match
â”‚   - /list_museums
â”‚   - /metadata/{museum}/{file}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ—‚ï¸ Data Layer
â”‚  - images/
â”‚  - embeddings.npy
â”‚  - pose_embeddings.npy
â”‚  - embeddings_meta.csv
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## 9. Outcome Demonstration
https://vimeo.com/1138944508

## 10. Features
- **Motion Capture Input** â†’ extract pose landmarks (via MediaPipe).
- **Cross-modal Embeddings** â†’ fuse pose with personality traits (Big Five sliders).
- **Generative Output**:
  - *Visual*: Stylised image output (Diffusion/Dreambooth optional).
  - *Audio*: Soundscape generation (RAVE/AudioLM integration planned).
- **Ethics by Design**: consent gate, data retention toggle, bias awareness.

## 11. Credit
Author: Xinyi Zhang  
Programme: MSc Computing and Creative Industry  
Institute: UAL â€“ Creative Computing Institute  
Year: 2025  
